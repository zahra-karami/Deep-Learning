{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from joblib import dump, load\n",
    "from utility import loadData, signsLabels\n",
    "import time\n",
    "from time import perf_counter as timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters: \n",
      "{'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {'n_neighbors':[3,5,7,10,15],'leaf_size': [20, 30, 40],  'algorithm': [ 'auto']}\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "clf = GridSearchCV(neigh, param_grid , n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimized Parameters: \\n{}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       331\n",
      "           1       0.95      0.94      0.94       432\n",
      "           2       0.95      1.00      0.97       310\n",
      "           3       0.76      0.95      0.85       245\n",
      "           4       0.78      0.97      0.86       498\n",
      "           5       0.87      0.91      0.89       247\n",
      "           6       0.91      0.94      0.92       348\n",
      "           7       0.95      0.94      0.94       436\n",
      "           8       0.87      0.65      0.75       288\n",
      "          10       0.85      0.59      0.70       331\n",
      "          11       0.93      0.89      0.91       209\n",
      "          12       0.81      0.49      0.61       394\n",
      "          13       0.78      0.59      0.67       291\n",
      "          14       1.00      0.88      0.94       246\n",
      "          15       1.00      1.00      1.00       347\n",
      "          16       0.95      1.00      0.97       164\n",
      "          17       0.32      0.60      0.41       144\n",
      "          18       0.67      0.87      0.76       246\n",
      "          19       0.70      0.70      0.70       248\n",
      "          20       0.42      0.68      0.52       266\n",
      "          21       0.68      0.53      0.59       346\n",
      "          22       0.72      0.68      0.70       206\n",
      "          23       0.80      0.69      0.74       267\n",
      "          24       0.97      0.68      0.80       332\n",
      "\n",
      "    accuracy                           0.80      7172\n",
      "   macro avg       0.81      0.80      0.79      7172\n",
      "weighted avg       0.83      0.80      0.80      7172\n",
      "\n",
      "\n",
      "Accuracy: 0.8039598438371445\n",
      "Precision: 0.8039598438371445\n",
      "Recall: 0.8039598438371445\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report :\\n{}\\n\".format(metrics.classification_report(y_test, y_pred)))\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred , average='micro'))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/KNN_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'models/KNN_model.joblib'\n",
    "dump(clf, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>K</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.797590</td>\n",
       "      <td>0.946136</td>\n",
       "      <td>0.950920</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.703252</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.676580</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.80396</td>\n",
       "      <td>0.809835</td>\n",
       "      <td>0.826044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.965863</td>\n",
       "      <td>0.910931</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.586103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.697581</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.526012</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.689139</td>\n",
       "      <td>0.680723</td>\n",
       "      <td>0.80396</td>\n",
       "      <td>0.797957</td>\n",
       "      <td>0.803960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.887399</td>\n",
       "      <td>0.940629</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.845173</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.923729</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759717</td>\n",
       "      <td>0.700405</td>\n",
       "      <td>0.520984</td>\n",
       "      <td>0.591870</td>\n",
       "      <td>0.698254</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.80396</td>\n",
       "      <td>0.793191</td>\n",
       "      <td>0.804562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>0.80396</td>\n",
       "      <td>7172.000000</td>\n",
       "      <td>7172.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A           B           C           D           E  \\\n",
       "precision    0.797590    0.946136    0.950920    0.763158    0.775806   \n",
       "recall       1.000000    0.935185    1.000000    0.946939    0.965863   \n",
       "f1-score     0.887399    0.940629    0.974843    0.845173    0.860465   \n",
       "support    331.000000  432.000000  310.000000  245.000000  498.000000   \n",
       "\n",
       "                    F           G           H           I           K  ...  \\\n",
       "precision    0.872093    0.908333    0.953271    0.870370    0.854626  ...   \n",
       "recall       0.910931    0.939655    0.935780    0.652778    0.586103  ...   \n",
       "f1-score     0.891089    0.923729    0.944444    0.746032    0.695341  ...   \n",
       "support    247.000000  348.000000  436.000000  288.000000  331.000000  ...   \n",
       "\n",
       "                    S           T           U           V           W  \\\n",
       "precision    0.671875    0.703252    0.423529    0.676580    0.717949   \n",
       "recall       0.873984    0.697581    0.676692    0.526012    0.679612   \n",
       "f1-score     0.759717    0.700405    0.520984    0.591870    0.698254   \n",
       "support    246.000000  248.000000  266.000000  346.000000  206.000000   \n",
       "\n",
       "                    X           Y  accuracy    macro avg  weighted avg  \n",
       "precision    0.796537    0.965812   0.80396     0.809835      0.826044  \n",
       "recall       0.689139    0.680723   0.80396     0.797957      0.803960  \n",
       "f1-score     0.738956    0.798587   0.80396     0.793191      0.804562  \n",
       "support    267.000000  332.000000   0.80396  7172.000000   7172.000000  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "columns = list(signsLabels().values())\n",
    "df = pd.DataFrame(report)\n",
    "columns.extend(['accuracy','macro avg','weighted avg'])\n",
    "df.columns = columns\n",
    "df.to_csv('output/KNN_classification_report.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
