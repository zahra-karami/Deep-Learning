# Sign Language Detection


<p>
<div>This Repository includes implementation of Sign Language Detection using Python and MNIST dataset </div>
<div>
        <b>   Problem Statement</b><hr/>
     
A robust visual recognition algorithm can help the deaf and hard-of-hearing better communicate using computer vision applications. The National Institute on Deafness and other Communications Disorders (NIDCD) indicates that the 200-year-old American Sign Language is a complete, complex language (of which letter gestures are only part) but is the primary language for many deaf North Americans. ASL is the leading minority language in the U.S. after the "big four": Spanish, Italian, German, and French. One could implement computer vision in an inexpensive board computer like Raspberry Pi with OpenCV, and some Text-to-Speech to enabling improved and automated translation applications.
</div>
<div>
    <b>  Dataset</b> <hr/>
    < a href="https://www.kaggle.com/datamunge/sign-language-mnist">https://www.kaggle.com/datamunge/sign-language-mnist</a>
Description:<hr/>
In dataset. each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The dataset consists 34627 samples which represent a single 28x28 pixel image with grayscale values between 0-255.
</div>
    
<div>
 <b>  Models / Architectures</b> <hr/>       
A Convolutional Neural Network (CNN) will be used as the deep learning method of choice for detecting the Sign Language. For the comparison methods, the Random Forest, k-Nearest Neighbors (KNN) and Support Vector Machines (SVM) have been used.

</div>
</p>
