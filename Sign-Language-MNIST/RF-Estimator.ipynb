{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from joblib import dump, load\n",
    "from utility import loadData, signsLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters: \n",
      "{'criterion': 'gini', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [20, 50, 100],  'criterion': ['gini'] }\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(rfc, param_grid , n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimized Parameters: \\n{}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       331\n",
      "           1       0.96      0.93      0.94       432\n",
      "           2       0.94      0.99      0.96       310\n",
      "           3       0.89      0.95      0.92       245\n",
      "           4       0.89      0.95      0.92       498\n",
      "           5       0.93      0.92      0.92       247\n",
      "           6       0.91      0.83      0.87       348\n",
      "           7       1.00      0.94      0.97       436\n",
      "           8       0.80      0.72      0.76       288\n",
      "          10       0.72      0.69      0.70       331\n",
      "          11       0.81      0.99      0.89       209\n",
      "          12       0.82      0.68      0.75       394\n",
      "          13       0.73      0.52      0.61       291\n",
      "          14       0.96      0.87      0.91       246\n",
      "          15       0.90      1.00      0.95       347\n",
      "          16       0.90      0.98      0.94       164\n",
      "          17       0.32      0.62      0.43       144\n",
      "          18       0.55      0.79      0.65       246\n",
      "          19       0.54      0.79      0.64       248\n",
      "          20       0.73      0.64      0.68       266\n",
      "          21       0.81      0.55      0.65       346\n",
      "          22       0.54      0.69      0.60       206\n",
      "          23       0.82      0.68      0.74       267\n",
      "          24       0.91      0.58      0.71       332\n",
      "\n",
      "    accuracy                           0.81      7172\n",
      "   macro avg       0.80      0.80      0.79      7172\n",
      "weighted avg       0.83      0.81      0.81      7172\n",
      "\n",
      "\n",
      "Accuracy: 0.8096765197992192\n",
      "Precision: 0.8096765197992192\n",
      "Recall: 0.8096765197992192\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report :\\n{}\\n\".format(metrics.classification_report(y_test, y_pred)))\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred , average='micro'))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/RF_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'models/RF_model.joblib'\n",
    "dump(clf, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>K</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.924581</td>\n",
       "      <td>0.961631</td>\n",
       "      <td>0.935976</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.890566</td>\n",
       "      <td>0.926531</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.997555</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554286</td>\n",
       "      <td>0.541209</td>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.535581</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.804279</td>\n",
       "      <td>0.829140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928241</td>\n",
       "      <td>0.990323</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.947791</td>\n",
       "      <td>0.919028</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.794355</td>\n",
       "      <td>0.635338</td>\n",
       "      <td>0.549133</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>0.677903</td>\n",
       "      <td>0.581325</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.803563</td>\n",
       "      <td>0.809677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.960813</td>\n",
       "      <td>0.944641</td>\n",
       "      <td>0.962382</td>\n",
       "      <td>0.915187</td>\n",
       "      <td>0.918288</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.870871</td>\n",
       "      <td>0.965680</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651007</td>\n",
       "      <td>0.643791</td>\n",
       "      <td>0.681452</td>\n",
       "      <td>0.652921</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>0.709559</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.794752</td>\n",
       "      <td>0.811415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>7172.000000</td>\n",
       "      <td>7172.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A           B           C           D           E  \\\n",
       "precision    0.924581    0.961631    0.935976    0.885496    0.890566   \n",
       "recall       1.000000    0.928241    0.990323    0.946939    0.947791   \n",
       "f1-score     0.960813    0.944641    0.962382    0.915187    0.918288   \n",
       "support    331.000000  432.000000  310.000000  245.000000  498.000000   \n",
       "\n",
       "                    F           G           H           I           K  ...  \\\n",
       "precision    0.926531    0.911950    0.997555    0.796154    0.721519  ...   \n",
       "recall       0.919028    0.833333    0.935780    0.718750    0.688822  ...   \n",
       "f1-score     0.922764    0.870871    0.965680    0.755474    0.704791  ...   \n",
       "support    247.000000  348.000000  436.000000  288.000000  331.000000  ...   \n",
       "\n",
       "                    S           T           U           V           W  \\\n",
       "precision    0.554286    0.541209    0.734783    0.805085    0.535581   \n",
       "recall       0.788618    0.794355    0.635338    0.549133    0.694175   \n",
       "f1-score     0.651007    0.643791    0.681452    0.652921    0.604651   \n",
       "support    246.000000  248.000000  266.000000  346.000000  206.000000   \n",
       "\n",
       "                    X           Y  accuracy    macro avg  weighted avg  \n",
       "precision    0.819005    0.910377  0.809677     0.804279      0.829140  \n",
       "recall       0.677903    0.581325  0.809677     0.803563      0.809677  \n",
       "f1-score     0.741803    0.709559  0.809677     0.794752      0.811415  \n",
       "support    267.000000  332.000000  0.809677  7172.000000   7172.000000  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "columns = list(signsLabels().values())\n",
    "df = pd.DataFrame(report)\n",
    "columns.extend(['accuracy','macro avg','weighted avg'])\n",
    "df.columns = columns\n",
    "df.to_csv('output/RF_classification_report.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
